{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r3/t2r07q612snc9xmhh7_6wkqm0000gn/T/ipykernel_31937/4232924142.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from telethon.sync import TelegramClient\n",
    "from telethon.tl.types import PeerUser, PeerChat, PeerChannel, InputMessagesFilterPhotoVideo\n",
    "from telethon.tl.functions.channels import GetFullChannelRequest\n",
    "import json\n",
    "import re\n",
    "from telethon.errors import ChannelPrivateError\n",
    "import pickle\n",
    "import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../credentials/credentials.pickle','rb') as file:\n",
    "    api_id, api_hash, phone, username = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_edgelist = pd.read_csv('../first_edgelist/first_edgelist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start building a dictionnaire id_to_names and id_to_description.\n",
    "We start from 'forward_to' of the first edgelist (there will be only Azione Incel and FDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dictionaires/id_to_names.json', 'r') as file:\n",
    "    id_to_names = json.load(file)\n",
    "\n",
    "with open('../dictionaires/id_to_desc.json', 'r') as file:\n",
    "    id_to_desc = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_names = dict(map(lambda x: (int(x[0]), x[1]),id_to_names.items())) #cast into integer\n",
    "id_to_desc = dict(map(lambda x: (int(x[0]), x[1]),id_to_desc.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = np.setdiff1d(first_edgelist['forward_from'], first_edgelist['forward_to'])\n",
    "#get only values in \"forward_from\" that ARE NOT in \"forward_to\" because we already did every \"forward_to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1049507817, 1049610340, 1114912074, 1187620806, 1190986829,\n",
       "       1215292658, 1223843057, 1235541026, 1301711481, 1301962344,\n",
       "       1309409559, 1317214607, 1323992627, 1332218554, 1366782055,\n",
       "       1378694795, 1392759909, 1400689598, 1422594647, 1422646676,\n",
       "       1550242102, 1564012790, 1572171702, 1603259782, 1606254367,\n",
       "       1606625424, 1614269632, 1646446376, 1655979710, 1668678283,\n",
       "       1700352017, 1724328030, 1731141767, 1768292617, 1772238161,\n",
       "       1783986700, 1804905770, 1850631337, 1862724187, 1910155003,\n",
       "       1958703743, 1969251461, 1970256187, 1973090987, 1997883763,\n",
       "       2083183611, 2085605636])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1832870539: '',\n",
       " 1259484976: 'Canale di informazione antifascista - Combatti la paura, distruggi il fascismo!\\nPotete mandarci segnalazioni o contributi a: \\n✨https://t.me/AzioneAntifaRmEst_Bot'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_date = datetime.datetime(2023,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels_forward(lista_messaggi, receving_id):\n",
    "    \"\"\"\n",
    "    lista_messaggi: list of patched telethon messages\n",
    "    receving_id: id of the scraped group. So the forwarded_to id\n",
    "\n",
    "    returns list of tuple with format (forwarded_from, forwarded_to)\n",
    "    where forwarded_to is the receving_id\n",
    "\n",
    "    \"\"\"\n",
    "    lista_fwd = []\n",
    "    for mex in lista_messaggi:\n",
    "        dict_mex = mex.to_dict()\n",
    "        if 'fwd_from' in dict_mex.keys() and dict_mex['fwd_from'] is not None:\n",
    "            fwd_info = dict_mex['fwd_from']['from_id']\n",
    "            if type(fwd_info) == dict and fwd_info['_']=='PeerChannel':\n",
    "                lista_fwd.append((fwd_info['channel_id'], receving_id))\n",
    "\n",
    "    return lista_fwd\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_data_channel(channel_id, offset_date, names_dict, desc_dict):\n",
    "    \"\"\"\n",
    "    Get all messages from channel NEWER than offset date (e.g. sent after offset date)\n",
    "\n",
    "    args:\n",
    "\n",
    "    channel_id: id of channel to be scraped (has to be an integer!)\n",
    "    offset_date: date limit \n",
    "    names_dict: dict of id-to-names\n",
    "    desc_dict: dict of id-to-bio\n",
    "    \n",
    "    return list of patcthed messages\n",
    "    \"\"\"\n",
    "    \n",
    "    async with TelegramClient(username, api_id, api_hash) as client:\n",
    "                entity = await client.get_entity(PeerChannel(channel_id))\n",
    "                full_entity = await client(GetFullChannelRequest(channel=entity))\n",
    "\n",
    "                names_dict[channel_id] = entity.title #get group name\n",
    "                desc_dict[channel_id] = full_entity.full_chat.about #get group bio\n",
    "\n",
    "                lista_mex = await client.get_messages(entity, reverse=True, offset_date=offset_date, limit=None)\n",
    "    \n",
    "    return lista_mex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if glob.glob('../temporary_data/*.pickle'):\n",
    "    with open('../temporary_data/temporary_third_edgelist.pickle','rb') as file_edgelist,\\\n",
    "        open('../temporary_data/temporary_id_to_names.pickle','rb') as file_id_names,\\\n",
    "        open('../temporary_data/temporary_id_to_desc.pickle','rb') as file_id_desc,\\\n",
    "        open('../temporary_data/temporary_index.pickle','rb') as index_file:\n",
    "\n",
    "            third_edgelist_list = pickle.load(file_edgelist)\n",
    "            id_to_names = pickle.load(file_id_names)\n",
    "            id_to_desc = pickle.load(file_id_desc)\n",
    "            index = pickle.load(index_file)\n",
    "\n",
    "else:\n",
    "    second_edgelist_list = []\n",
    "    index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [08:51<00:00, 11.32s/it]\n"
     ]
    }
   ],
   "source": [
    "start_value = index\n",
    "final_value = len(unique_values)\n",
    "for index in tqdm.tqdm(range(start_value,final_value)):\n",
    "    codice = unique_values[index]\n",
    "    try:\n",
    "        list_messages = await get_data_channel(int(codice), offset_date, id_to_names, id_to_desc)\n",
    "        list_tuples = get_channels_forward(list_messages, codice)\n",
    "        second_edgelist_list.extend(list_tuples)\n",
    "    except(ChannelPrivateError, ValueError) as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_from = list(map(lambda x: x[0], second_edgelist_list))\n",
    "forward_to = list(map(lambda x: x[1], second_edgelist_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_edgelist_df_raw = pd.DataFrame({'forward_from':forward_from,\\\n",
    "    'forward_to':forward_to})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save edgelist\n",
    "second_edgelist = second_edgelist_df_raw.value_counts().reset_index()\n",
    "second_edgelist.to_csv('../second_edgelist/second_edgelist.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to cast keys as int (instead of int64) to dump json\n",
    "id_to_names_int = dict(map(lambda x: (int(x[0]),x[1]),id_to_names.items()))\n",
    "id_to_desc_int = dict(map(lambda x: (int(x[0]),x[1]),id_to_desc.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dictionaires/id_to_names.json','w') as file_names, \\\n",
    "    open('../dictionaires/id_to_desc.json','w') as file_desc:\n",
    "    json.dump(id_to_names_int, file_names)\n",
    "    json.dump(id_to_desc_int, file_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
