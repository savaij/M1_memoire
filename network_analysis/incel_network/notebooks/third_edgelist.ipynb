{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from telethon.sync import TelegramClient\n",
    "from telethon.tl.types import PeerUser, PeerChat, PeerChannel, InputMessagesFilterPhotoVideo\n",
    "from telethon.tl.functions.channels import GetFullChannelRequest\n",
    "import json\n",
    "import re\n",
    "from telethon.errors import ChannelPrivateError\n",
    "import tqdm\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../credentials/credentials.pickle','rb') as file:\n",
    "    api_id, api_hash, phone, username = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_edgelist = pd.read_csv('../first_edgelist/first_edgelist_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_edgelist = pd.read_csv('../second_edgelist/second_edgelist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist_total = pd.concat([first_edgelist, second_edgelist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = np.setdiff1d(second_edgelist['forward_from'], edgelist_total['forward_to'])\n",
    "#get only values from second iteration that are NOT in the total edgelist 'forward_to' column \n",
    "#because we have already done every 'forward_to' channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_date = datetime.datetime(2023,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels_forward(lista_messaggi, receving_id):\n",
    "    \"\"\"\n",
    "    lista_messaggi: list of patched telethon messages\n",
    "    receving_id: id of the scraped group. So the forwarded_to id\n",
    "\n",
    "    returns list of tuple with format (forwarded_from, forwarded_to)\n",
    "    where forwarded_to is the receving_id\n",
    "\n",
    "    \"\"\"\n",
    "    lista_fwd = []\n",
    "    for mex in lista_messaggi:\n",
    "        dict_mex = mex.to_dict()\n",
    "        if 'fwd_from' in dict_mex.keys() and dict_mex['fwd_from'] is not None:\n",
    "            fwd_info = dict_mex['fwd_from']['from_id']\n",
    "            if type(fwd_info) == dict and fwd_info['_']=='PeerChannel':\n",
    "                lista_fwd.append((fwd_info['channel_id'], receving_id))\n",
    "\n",
    "    return lista_fwd\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get dictionaires so we can upload them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dictionaires/id_to_names.json', 'r') as file:\n",
    "    id_to_names = json.load(file)\n",
    "\n",
    "with open('../dictionaires/id_to_desc.json', 'r') as file:\n",
    "    id_to_desc = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_data_channel(channel_id, offset_date, names_dict, desc_dict):\n",
    "    \"\"\"\n",
    "    Get all messages from channel NEWER than offset date (e.g. sent after offset date)\n",
    "\n",
    "    args:\n",
    "\n",
    "    channel_id: id of channel to be scraped (has to be an integer!)\n",
    "    offset_date: date limit \n",
    "    names_dict: dict of id-to-names\n",
    "    desc_dict: dict of id-to-bio\n",
    "    \n",
    "    return list of patcthed messages\n",
    "    \"\"\"\n",
    "    \n",
    "    async with TelegramClient(username, api_id, api_hash) as client:\n",
    "                entity = await client.get_entity(PeerChannel(channel_id))\n",
    "                full_entity = await client(GetFullChannelRequest(channel=entity))\n",
    "\n",
    "                names_dict[channel_id] = entity.title #get group name\n",
    "                desc_dict[channel_id] = full_entity.full_chat.about #get group bio\n",
    "\n",
    "                lista_mex = await client.get_messages(entity, reverse=True, offset_date=offset_date, limit=None)\n",
    "    \n",
    "    return lista_mex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check if there are temporary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if glob.glob('../temporary_data/*.pickle'):\n",
    "    with open('../temporary_data/temporary_third_edgelist.pickle','rb') as file_edgelist,\\\n",
    "        open('../temporary_data/temporary_id_to_names.pickle','rb') as file_id_names,\\\n",
    "        open('../temporary_data/temporary_id_to_desc.pickle','rb') as file_id_desc,\\\n",
    "        open('../temporary_data/temporary_index.pickle','rb') as index_file:\n",
    "\n",
    "            third_edgelist_list = pickle.load(file_edgelist)\n",
    "            id_to_names = pickle.load(file_id_names)\n",
    "            id_to_desc = pickle.load(file_id_desc)\n",
    "            index = pickle.load(index_file)\n",
    "\n",
    "else:\n",
    "    third_edgelist_list = []\n",
    "    index=0\n",
    "    #dictionaires would be already saved as variables because of the other cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 37/48 [11:17<00:53,  4.91s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The channel specified is private and you lack permission to access it. Another reason may be that you were banned from it (caused by GetChannelsRequest)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [13:20<00:00, 16.67s/it]\n"
     ]
    }
   ],
   "source": [
    "start_value = index\n",
    "final_value = len(unique_values)\n",
    "for index in tqdm.tqdm(range(start_value, final_value)):\n",
    "    codice = unique_values[index]\n",
    "    try:\n",
    "        list_messages = await get_data_channel(int(codice), offset_date, id_to_names, id_to_desc)\n",
    "        list_tuples = get_channels_forward(list_messages, codice)\n",
    "        third_edgelist_list.extend(list_tuples)\n",
    "    except(ChannelPrivateError, ValueError) as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./temporary_data/temporary_third_edgelist.pickle','wb') as file_edgelist,\\\n",
    "    open('./temporary_data/temporary_id_to_names.pickle','wb') as file_id_names,\\\n",
    "        open('./temporary_data/temporary_id_to_desc.pickle','wb') as file_id_desc,\\\n",
    "        open('./temporary_data/temporary_index.pickle','wb') as index_file:\n",
    "\n",
    "        pickle.dump(third_edgelist_list, file_edgelist)\n",
    "        pickle.dump(id_to_names, file_id_names)\n",
    "        pickle.dump(id_to_desc, file_id_desc)\n",
    "        pickle.dump(index, index_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> \n",
    "<summary>code to execute if we interrupt the iteration</summary>\n",
    "\n",
    "\n",
    "``` python\n",
    "with open('./temporary_data/temporary_third_edgelist.pickle','wb') as file_edgelist,\\\n",
    "    open('./temporary_data/temporary_id_to_names.pickle','wb') as file_id_names,\\\n",
    "        open('./temporary_data/temporary_id_to_desc.pickle','wb') as file_id_desc,\\\n",
    "        open('./temporary_data/temporary_index.pickle','wb') as index_file:\n",
    "\n",
    "        pickle.dump(third_edgelist_list, file_edgelist)\n",
    "        pickle.dump(id_to_names, file_id_names)\n",
    "        pickle.dump(id_to_desc, file_id_desc)\n",
    "        pickle.dump(index, index_file)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../temporary_data/temporary_third_edgelist.pickle','wb') as file_edgelist,\\\n",
    "    open('../temporary_data/temporary_id_to_names.pickle','wb') as file_id_names,\\\n",
    "        open('../temporary_data/temporary_id_to_desc.pickle','wb') as file_id_desc,\\\n",
    "        open('../temporary_data/temporary_index.pickle','wb') as index_file:\n",
    "\n",
    "        pickle.dump(third_edgelist_list, file_edgelist)\n",
    "        pickle.dump(id_to_names, file_id_names)\n",
    "        pickle.dump(id_to_desc, file_id_desc)\n",
    "        pickle.dump(index, index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_from = list(map(lambda x: x[0], third_edgelist_list))\n",
    "forward_to = list(map(lambda x: x[1], third_edgelist_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_edgelist_df_raw = pd.DataFrame({'forward_from':forward_from,\\\n",
    "    'forward_to':forward_to})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_edgelist = third_edgelist_df_raw.value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_edgelist.to_csv('../third_edgelist/third_edgelist.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_names_int = dict(map(lambda x: (int(x[0]),x[1]),id_to_names.items()))\n",
    "id_to_desc_int = dict(map(lambda x: (int(x[0]),x[1]),id_to_desc.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dictionaires/id_to_names.json','w') as file_names, \\\n",
    "    open('../dictionaires/id_to_desc.json','w') as file_desc:\n",
    "    json.dump(id_to_names_int, file_names)\n",
    "    json.dump(id_to_desc_int, file_desc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
